# ğŸ” TruthLens AI

**Multimodal Fake News Detection System using BERT and EfficientNet**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Gradio](https://img.shields.io/badge/Gradio-4.0+-orange.svg)](https://gradio.app/)

> Advanced AI system combining BERT text analysis (84.5% accuracy) and EfficientNet image detection (97.66% accuracy) to combat misinformation on social media platforms.

---

## ğŸ“Š Performance Highlights

| Component | Model | Accuracy | Key Metric | Status |
|-----------|-------|----------|------------|--------|
| **Text Analysis** | BERT-base | **84.5%** | Recall: 83.3% | âœ… Deployed |
| **Image Analysis** | EfficientNet-B0 | **97.66%** | ROC AUC: 0.9971 | ğŸ”¬ Research |
| **Baseline (SVM)** | Linear SVM | 75.7% | Recall: 63.3% | ğŸ“Š Comparison |

**Key Achievements:**
- ğŸ¯ **20-point recall improvement** (63.3% â†’ 83.3%) reducing missed fake news by 44%
- ğŸ–¼ï¸ **Near-perfect image detection** (ROC AUC: 0.9971) with only 2.34% error rate
- âš¡ **Real-time inference** (<1 second response time)
- ğŸ“ˆ **+11.6% improvement** over traditional ML baselines

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/TruthLens-AI.git
cd TruthLens-AI

# Install dependencies
pip install -r requirements.txt

# Download models (if not using Git LFS)
# See docs/SETUP.md for model download links
```

### Run the Chatbot

```bash
python src/chatbot.py
```

Then open the Gradio interface in your browser!

---

## ğŸ’¡ Features

### Text Analysis (Production)
- âœ… BERT-based fake news detection
- âœ… Detects clickbait and sensational language
- âœ… Identifies emotional manipulation tactics
- âœ… Real-time confidence scoring
- âœ… Detailed pattern explanations

### Image Analysis (Research Phase)
- ğŸ”¬ AI-generated image detection
- ğŸ”¬ 97.66% accuracy on CIFAKE dataset
- ğŸ”¬ Near-perfect ROC AUC (0.9971)
- ğŸ”¬ Balanced real vs. synthetic detection
- ğŸ”¬ Production deployment planned (Phase 2)

### Interactive Chatbot
- ğŸ’¬ Conversational AI interface
- ğŸ“ Natural language interaction
- ğŸ¯ Sample headlines for testing
- ğŸ“Š Visual confidence displays
- â“ Built-in help system

---

## ğŸ“ Repository Structure

```
TruthLens-AI/
â”œâ”€â”€ docs/                              # Documentation and reports
â”‚   â”œâ”€â”€ Final_Project_Report.pdf      # Complete academic report
â”‚   â”œâ”€â”€ SETUP.md                       # Installation guide
â”‚   â””â”€â”€ USAGE.md                       # Usage instructions
â”‚
â”œâ”€â”€ notebooks/                         # Jupyter notebooks
â”‚   â”œâ”€â”€ text_classification/          # Text analysis pipeline
â”‚   â”‚   â”œâ”€â”€ 01_EDA_visualizations.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_Baseline_Model_Training.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_BERT_Training.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_Fakeddit_Setup.ipynb
â”‚   â”‚   â””â”€â”€ 05_TruthLens_Chatbot.ipynb
â”‚   â”‚
â”‚   â””â”€â”€ image_classification/         # Image analysis pipeline
â”‚       â””â”€â”€ image_classification.ipynb
â”‚
â”œâ”€â”€ models/                            # Trained model files
â”‚   â”œâ”€â”€ text_models/
â”‚   â”‚   â”œâ”€â”€ linear_svm_model.pkl      # SVM baseline 
â”‚   â”‚   â”œâ”€â”€ naive_bayes_model.pkl     # Naive Bayes baseline 
â”‚   â”‚   â””â”€â”€ logistic_regression_model.pkl  # Logistic Regression 
â”‚
â”‚   Note: Large models (BERT, Random Forest and EfficientNet) available via Google Drive
â”‚   See "Model Downloads" section below
â”‚
â”œâ”€â”€ results/                           # Training and evaluation results
â”‚   â”œâ”€â”€ text_classification/
â”‚   â”‚   â”œâ”€â”€ EDA/                      # Exploratory data analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_label_distribution.png
â”‚   â”‚   â”‚   â”œâ”€â”€ 02_text_analysis.png
â”‚   â”‚   â”‚   â”œâ”€â”€ 03_word_frequency.png
â”‚   â”‚   â”‚   â”œâ”€â”€ sample_posts.csv
â”‚   â”‚   â”‚   â””â”€â”€ summary_statistics.csv
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Baseline/                 # Baseline model results
â”‚   â”‚   â”‚   â”œâ”€â”€ baseline_comparison.png
â”‚   â”‚   â”‚   â”œâ”€â”€ baseline_results.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ best_baseline_confusion_matrix.png
â”‚   â”‚   â”‚   â””â”€â”€ my_results.png
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ BERT/                     # BERT model results
â”‚   â”‚       â”œâ”€â”€ baseline_vs_bert.png
â”‚   â”‚       â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚       â”œâ”€â”€ final_comparison.csv
â”‚   â”‚       â””â”€â”€ training_history.png
â”‚   â”‚
â”‚   â””â”€â”€ image_classification/         # Image classification results
â”‚       â”œâ”€â”€ confusion_matrix.png
â”‚       â”œâ”€â”€ roc_curve.png
â”‚       â”œâ”€â”€ precision_recall_curve.png
â”‚       â”œâ”€â”€ per_class_metrics.png
â”‚       â”œâ”€â”€ error_distribution.png
â”‚       â”œâ”€â”€ confidence_analysis.png
â”‚       â”œâ”€â”€ training_history_fast.png
â”‚       â””â”€â”€ evaluation_summary.txt
â”‚
â””â”€â”€ requirements.txt                   # Python dependencies

```

---

## ğŸ¯ System Architecture

### Current Implementation (Text-Only)

```
User Input (Text Headline)
        â†“
    BERT Model
   (84.5% acc)
        â†“
   Prediction + Confidence
        â†“
  Pattern Detection
        â†“
  Detailed Analysis
        â†“
  Gradio Interface
```

### Planned Multimodal System (Phase 2)

```
User Input
    â†“
Text + Image
    â†“         â†“
  BERT    EfficientNet
 (84.5%)   (97.66%)
    â†“         â†“
Confidence Weighted Fusion
         â†“
  Combined Verdict
         â†“
   Gradio Interface
```

---

## ğŸ§  Models & Performance

### Text Classification (BERT)

**Dataset:** Fakeddit (45,414 Reddit posts)
- Training: 27,248 samples
- Validation: 9,083 samples
- Test: 9,083 samples

**Performance:**
| Metric | Score |
|--------|-------|
| Accuracy | **84.5%** |
| Precision | 81.4% |
| Recall | **83.3%** |
| F1-Score | 82.4% |

**Baseline Comparison:**
- Linear SVM: 75.7%
- TruthLens (BERT): **84.5%**
- Improvement: **+8.8 points (+11.6%)**

**Training:**
- Model: `bert-base-uncased` (110M parameters)
- Hardware: Tesla T4 GPU
- Time: 35 minutes (2 epochs)
- Framework: PyTorch + Transformers

### Image Classification (EfficientNet-B0)

**Dataset:** CIFAKE (120,000 images)
- Training: ~25,000 samples (30% optimized subset)
- Validation: ~7,500 samples
- Test: 15,000 samples (full test set)

**Performance:**
| Metric | Score |
|--------|-------|
| Test Accuracy | **97.66%** |
| ROC AUC | **0.9971** |
| Precision | 97.66% |
| Recall | 97.66% |
| Error Rate | **2.34%** |

**Per-Class Performance:**
- Real Images: 97.31% detection rate
- AI-Generated: 98.01% detection rate

**Training:**
- Model: EfficientNet-B0 (5.3M parameters)
- Hardware: Tesla T4 GPU
- Time: 14.4 minutes (9 epochs with early stopping)
- Framework: PyTorch + TorchVision

---

## ğŸ® Demo & Usage

### TruthLens AI Chatbot

Launch the interactive chatbot:

```bash
python src/chatbot.py
```

**Features:**
- ğŸ’¬ Natural conversational interface
- ğŸ“ Analyze news headlines in real-time
- ğŸ¯ Pre-loaded sample headlines
- ğŸ“Š Confidence visualizations
- â“ Built-in help and guidance

**Sample Interaction:**
```
User: "BREAKING: Scientists discover miracle cure that works 100% of the time!!!"

TruthLens AI:
ğŸš¨ HIGH RISK - Likely Fake News
Confidence: 92.3%

Red Flags Detected:
- Sensational: breaking
- Exaggerated: miracle, 100%
- Emotional: !!!

Recommendation: Strong indicators of misinformation. Fact-check before sharing.
```

### Programmatic Usage

**Text Analysis:**
```python
from src.text_classifier import TextClassifier

classifier = TextClassifier(model_path='models/text_models/bert_best_model.pt')
result = classifier.predict("Your headline here")

print(f"Prediction: {result['prediction']}")
print(f"Confidence: {result['confidence']:.1f}%")
```

**Image Analysis:**
```python
from src.image_classifier import ImageClassifier

classifier = ImageClassifier(model_path='models/image_models/best_efficientnet_cifake_fast.pth')
result = classifier.predict("path/to/image.jpg")

print(f"Prediction: {result['prediction']}")
print(f"Confidence: {result['confidence']:.1f}%")
```

---

## ğŸ“š Documentation

- **[Setup Guide](docs/SETUP.md)** - Detailed installation instructions
- **[Usage Guide](docs/USAGE.md)** - How to use the system
- **[Full Report](docs/Final_Project_Report.pdf)** - Complete academic report with methodology, results, and analysis

---

## ğŸ”¬ Research Highlights

### Key Findings

1. **BERT Superiority:** Fine-tuned BERT achieves 84.5% accuracy, substantially outperforming classical ML baselines (75.7%) on short social media text.

2. **Recall Breakthrough:** 20-point recall improvement (63.3% â†’ 83.3%) represents 44% reduction in missed fake newsâ€”critical for content moderation.

3. **Near-Perfect Image Detection:** EfficientNet-B0 achieves 0.9971 ROC AUC, demonstrating exceptional discrimination between real and AI-generated images.

4. **Short Text Challenge:** Average headline length of 8.1 words creates challenging classification environment where traditional methods plateau at ~75%.

5. **Commercial Viability:** Identified $600-900M annual market opportunity with 60% cost reduction vs. manual fact-checking.

### Methodology

**Text Classification Pipeline:**
1. Dataset: Fakeddit (45,414 Reddit posts)
2. Preprocessing: BERT tokenization (max 128 tokens)
3. Training: Fine-tuning with AdamW optimizer (2e-5 learning rate)
4. Evaluation: Comprehensive metrics on held-out test set

**Image Classification Pipeline:**
1. Dataset: CIFAKE (120,000 real and AI-generated images)
2. Preprocessing: Data augmentation, ImageNet normalization
3. Training: Transfer learning with EfficientNet-B0
4. Evaluation: 15,000-image test set with detailed analysis

---

## ğŸ“ˆ Results Visualization

### Text Classification

**Training Curves:**

![BERT Training History](results/text_classification/BERT/training_history.png)

**Performance Comparison:**

![Baseline vs BERT](results/text_classification/BERT/baseline_vs_bert.png)

**Confusion Matrix:**

![Confusion Matrix](results/text_classification/Bert/confusion_matrix.png)

### Image Classification

**ROC Curve (AUC: 0.9971):**

![ROC Curve](results/image_classification/roc_curve.png)

**Confusion Matrix:**

![Confusion Matrix](results/image_classification/confusion_matrix.png)

**Per-Class Metrics:**

![Per-Class Performance](results/image_classification/per_class_metrics.png)

---

## ğŸ› ï¸ Technical Stack

**Frameworks & Libraries:**
- PyTorch 2.0+
- Transformers (HuggingFace)
- TorchVision
- Gradio 4.0+
- scikit-learn
- Pandas, NumPy, Matplotlib, Seaborn

**Models:**
- **Text:** BERT-base-uncased (110M parameters)
- **Image:** EfficientNet-B0 (5.3M parameters)
- **Baselines:** SVM, Random Forest, Naive Bayes, Logistic Regression

**Hardware:**
- Training: NVIDIA Tesla T4 GPU (Google Colab)
- Inference: CPU/GPU compatible

---

## ğŸ“ Academic Context

**Course:** EAI6010 - Applications of AI  
**Institution:** Northeastern University  
**Term:** Fall Quarter 2025  
**Instructor:** Prof. Sergiy Shevchenko

**Team:**
- Abhijit More
- Kshama Upadhyay
- Qiwei Guo

---

## ğŸ“– Datasets

### Text: Fakeddit
- **Source:** [Fakeddit Dataset](https://github.com/entitize/Fakeddit)
- **Size:** 45,414 labeled Reddit posts
- **Classes:** Real (56.8%), Fake (43.2%)
- **Features:** Post titles/headlines
- **Citation:** Yang & Shu (2020)

### Image: CIFAKE
- **Source:** [CIFAKE on Kaggle](https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images)
- **Size:** 120,000 images (60K real, 60K AI-generated)
- **Resolution:** 32Ã—32 pixels RGB
- **Classes:** Real (CIFAR-10), AI-Generated (Stable Diffusion)
- **Citation:** Bird & Lotfi (2024)

*Note: Datasets not included in repository due to size. See [docs/dataset_info.md](docs/dataset_info.md) for download instructions.*

---

## ğŸ“¥ Model Downloads

Due to GitHub's file size limitations, large model files are hosted on Google Drive:

### Required Models

| Model | Size | Accuracy | Download | Destination |
|-------|------|----------|----------|-------------|
| **BERT Text Model** | 438 MB | 84.5% | ğŸ”— [Download](https://drive.google.com/file/d/1LDCPkeOLto4YC481aaW_nw4evSsiawxq/view?usp=sharing)

### Required Models

| Model | Size | Accuracy | Download | Destination |
|-------|------|----------|----------|-------------|
| **EfficientNet Image Model** | 438 MB | 97.6% | ğŸ”— [Download](https://drive.google.com/file/d/1zkygAG0wrWfyZoxTNdQSs4pCmTaWtqtR/view?usp=sharing)


### Optional Models

| Model | Size | Accuracy | Download | Destination |
|-------|------|----------|----------|-------------|
| **Random Forest Baseline** | 244 MB | 73.6% | ğŸ”— [Download](https://drive.google.com/file/d/18PErcIudGhEgnme8z9a1mmqDwodphFQz/view?usp=sharing)

### Included in Repository

These models are already included (no download needed):
- âœ… **EfficientNet-B0** (46.4 MB, 97.66% accuracy) - `models/image_models/`
- âœ… **Linear SVM** (41 KB) - `models/text_models/`
- âœ… **Naive Bayes** (161 KB) - `models/text_models/`
- âœ… **Logistic Regression** (41 KB) - `models/text_models/`

**After downloading:**
1. Place downloaded files in the specified destination folders
2. Verify file sizes match the table above
3. Run verification script in [SETUP.md](docs/SETUP.md)

---

## ğŸ”‘ Key Features

### âœ… Production-Ready (Deployed)
- **TruthLens AI Chatbot:** Conversational interface for headline analysis
- **Real-time Processing:** <1 second inference time
- **Explainability:** Detailed reasoning and pattern detection
- **Confidence Scoring:** Percentage-based reliability indicators
- **Sample Testing:** Pre-loaded examples for instant demo

### ğŸ”¬ Research Validated (Phase 2 Deployment)
- **Image Classification:** 97.66% accuracy on synthetic image detection
- **Multimodal Fusion:** Confidence-weighted algorithm designed
- **Comprehensive Evaluation:** ROC curves, confusion matrices, error analysis
- **Production-Grade Metrics:** 2.34% error rate, balanced performance

---

## ğŸ“Š Detailed Results

### Text Classification Metrics

**BERT Model Performance:**
```
Accuracy:  84.5%
Precision: 81.4%
Recall:    83.3%  â† Critical metric
F1-Score:  82.4%

Baseline (SVM): 75.7%
Improvement:    +8.8 points
```

**Confusion Matrix (Test Set, N=9,083):**
```
                Predicted
              Real    Fake
Actual Real   4,375    750
       Fake     658  3,286

False Negatives: 658 (17% miss rate)
False Positives: 750 (15% false alarm rate)
```

### Image Classification Metrics

**EfficientNet-B0 Performance:**
```
Test Accuracy:      97.66%
ROC AUC:            0.9971  â† Near-perfect
Average Precision:  0.9966
Error Rate:         2.34% (351/15,000)

Confidence (Correct):   98.94%
Confidence (Incorrect): 80.19%
Gap: 18.75 points (excellent calibration)
```

**Confusion Matrix (Test Set, N=15,000):**
```
                    Predicted
              Real        AI-Gen
Actual Real   7,298 (97.3%)  202 (2.7%)
       Fake     149 (2.0%)  7,351 (98.0%)

False Negatives: 149 (1.99% miss rate)
False Positives: 202 (2.69% false alarm)
```

---

## ğŸš¦ Project Status

### âœ… Completed
- [x] Comprehensive baseline evaluation (4 ML models)
- [x] BERT text classifier training and validation
- [x] EfficientNet image classifier training and evaluation
- [x] TruthLens AI chatbot deployment (text-only)
- [x] Complete academic report with market analysis
- [x] Production-ready inference pipeline

### ğŸ”„ In Progress
- [ ] High-resolution image dataset training
- [ ] Multimodal fusion implementation
- [ ] Real-world social media validation
- [ ] Adversarial robustness testing

### ğŸ“… Planned (Phase 2)
- [ ] Complete multimodal integration
- [ ] Image upload in chatbot interface
- [ ] Advanced fusion algorithms (attention-based)
- [ ] Multilingual expansion
- [ ] Browser extension development

---

## ğŸ’¼ Business Impact

### Market Opportunity
- **Total Addressable Market:** $600-900M annually
- **Target Customers:** Meta, Twitter/X, Google/YouTube, Amazon
- **Cost Reduction:** 60% vs. manual fact-checking
- **ROI:** 63% first year, 95% annually thereafter

### Commercial Applications
1. **Social Media Platforms:** Automated content moderation at scale
2. **News Organizations:** Pre-publication verification tools
3. **Fact-Checking Services:** Enhanced productivity (3-5Ã— faster)
4. **E-commerce:** Fake review and synthetic product image detection

---

## ğŸ”§ Installation & Setup

### Prerequisites
- Python 3.8 or higher
- CUDA-capable GPU (recommended, not required)
- 8GB RAM minimum
- 2GB free disk space

### Step-by-Step Installation

**1. Clone Repository**
```bash
git clone https://github.com/YOUR_USERNAME/TruthLens-AI.git
cd TruthLens-AI
```

**2. Create Virtual Environment (Recommended)**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

**3. Install Dependencies**
```bash
pip install -r requirements.txt
```

**4. Download Model Files**

Due to file size constraints, large models are hosted separately:

- **BERT Model (417 MB):** [Download from Google Drive](https://drive.google.com/file/d/1LDCPkeOLto4YC481aaW_nw4evSsiawxq/view?usp=sharing)
- **Random Forest (232 MB):** [Download from Google Drive](https://drive.google.com/file/d/18PErcIudGhEgnme8z9a1mmqDwodphFQz/view?usp=sharing)
- **EfficientNet:** [Download from Google Drive](https://drive.google.com/file/d/1zkygAG0wrWfyZoxTNdQSs4pCmTaWtqtR/view?usp=sharing)

Place downloaded models in respective `models/` subdirectories.

**5. Verify Installation**
```bash
python -c "import torch; from transformers import BertTokenizer; print('âœ“ Installation successful!')"
```

### Quick Test

```bash
# Run chatbot
python src/chatbot.py

# Expected output: Gradio URL (e.g., http://127.0.0.1:7860)
```

For detailed troubleshooting, see [docs/SETUP.md](docs/SETUP.md).

---

## ğŸ“– Usage Examples

### Command Line Interface

**Analyze Text:**
```python
from src.text_classifier import TextClassifier

# Initialize classifier
classifier = TextClassifier(
    model_path='models/text_models/bert_best_model.pt',
    device='cuda'  # or 'cpu'
)

# Analyze headline
headline = "BREAKING: Scientists discover miracle cure!"
result = classifier.predict(headline)

print(f"Prediction: {result['prediction']}")        # FAKE
print(f"Confidence: {result['confidence']:.1f}%")   # 92.3%
print(f"Real Prob: {result['real_prob']:.3f}")      # 0.077
print(f"Fake Prob: {result['fake_prob']:.3f}")      # 0.923
```

**Analyze Image:**
```python
from src.image_classifier import ImageClassifier

# Initialize classifier
classifier = ImageClassifier(
    model_path='models/image_models/best_efficientnet_cifake_fast.pth',
    device='cuda'
)

# Analyze image
result = classifier.predict("path/to/image.jpg")

print(f"Prediction: {result['prediction']}")        # AI-GENERATED
print(f"Confidence: {result['confidence']:.1f}%")   # 96.4%
print(f"Real Prob: {result['real_prob']:.3f}")      # 0.036
print(f"AI Prob: {result['ai_prob']:.3f}")          # 0.964
```

### Interactive Chatbot

```bash
# Launch chatbot
python src/chatbot.py

# Browser opens automatically to Gradio interface
# Try:
# - Type: "help" for usage guide
# - Type: "stats" for performance metrics
# - Paste headline for instant analysis
# - Click sample buttons for demos
```

---

## ğŸ§ª Reproducibility

### Training from Scratch

**Text Classification:**
```bash
# See notebooks/text_classification/03_BERT_Training.ipynb
# Or run training script (if you create one):
python scripts/train_text_model.py --epochs 2 --lr 2e-5
```

**Image Classification:**
```bash
# See notebooks/image_classification/02_EfficientNet_Training.ipynb
# Training completes in ~15 minutes on T4 GPU
```

### Evaluation

Run comprehensive evaluation:
```bash
# Text model
python scripts/evaluate_text.py

# Image model  
python scripts/evaluate_image.py
```

All evaluation notebooks are in `notebooks/` with detailed visualizations.

---

## ğŸ“„ Citation

If you use this work in your research, please cite:

```bibtex
@misc{truthlens2025,
  title={TruthLens AI: Multimodal Fake News Detection using BERT and EfficientNet},
  author={More, Abhijit and Upadhyay, Kshama and Guo, Qiwei},
  year={2025},
  institution={Northeastern University},
  course={EAI6010 - Applications of AI},
  note={Text: 84.5\% accuracy, Image: 97.66\% accuracy, ROC AUC: 0.9971}
}
```

---

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**Areas for contribution:**
- Multimodal integration implementation
- Additional language support
- Performance optimizations
- UI/UX improvements
- Additional datasets and benchmarks

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Datasets:** Fakeddit (Yang & Shu, 2020), CIFAKE (Bird & Lotfi, 2024)
- **Frameworks:** PyTorch, Transformers (HuggingFace), Gradio
- **Compute:** Google Colab Pro (free tier)
- **Instructor:** Prof. Sergiy Shevchenko
- **Institution:** Northeastern University

---

## ğŸ“ Contact

**For questions or collaboration:**
- ğŸ“§ Email: [more.ab@northeastern.edu]
- ğŸ’¼ LinkedIn: [https://www.linkedin.com/in/abhijitmore1407/]
- ğŸ™ GitHub: [@YOUR_USERNAME](https://github.com/Abhijit1407)

---

## â­ Star This Repository!

If you found this project helpful, please give it a star! It helps others discover this work.

---

<div align="center">

**Built with â¤ï¸ for combating misinformation**

[Report](docs/Final_Project_Report.pdf) â€¢ [Demo](src/chatbot.py) â€¢ [Docs](docs/)

</div>

---

## ğŸ“Š Repository Stats

![Code Size](https://img.shields.io/github/languages/code-size/Abhijit1407/TruthLens-AI)
![Last Commit](https://img.shields.io/github/last-commit/Abhijit1407/TruthLens-AI)
![Issues](https://img.shields.io/github/issues/Abhijit1407/TruthLens-AI)

---

**Last Updated:** January 2026  
**Version:** 1.0.0  
**Status:** Production (Text), Research (Image)
